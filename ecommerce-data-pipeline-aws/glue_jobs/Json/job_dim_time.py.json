{
	"jobConfig": {
		"name": "job_dim_time.py",
		"description": "",
		"role": "arn:aws:iam::822687513164:role/glue-role-ecommerce-pipeline",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "job_dim_time.py",
		"scriptLocation": "s3://aws-glue-assets-822687513164-eu-north-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-07-14T05:58:27.112Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-822687513164-eu-north-1/temporary/",
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-822687513164-eu-north-1/sparkHistoryLogs/",
		"maintenanceWindow": null
	},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "\"\"\"\nTitle: Glue Job â€“ Create dim_time from fact table\nAuthor: Milan Gabriel\nCreated: 2025-07-14\nDescription:\n    Builds a time dimension from distinct event_time values in the fact table.\n    Outputs Parquet to S3 for Athena access.\n\"\"\"\n\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.functions import (\n    year, month, dayofmonth, hour, dayofweek, weekofyear, quarter\n)\nimport sys\n\n# Glue Job Params\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\n# Read cleaned purchases data\ndf = spark.read.parquet(\"s3://ecommerce-pipeline-milan/clean/clickstream/purchases/\")\n\n# Build time dimension\ndim_time = (\n    df.select(\"event_time\").distinct()\n      .withColumn(\"year\", year(\"event_time\"))\n      .withColumn(\"month\", month(\"event_time\"))\n      .withColumn(\"day\", dayofmonth(\"event_time\"))\n      .withColumn(\"hour\", hour(\"event_time\"))\n      .withColumn(\"weekday\", dayofweek(\"event_time\"))\n      .withColumn(\"week\", weekofyear(\"event_time\"))\n      .withColumn(\"quarter\", quarter(\"event_time\"))\n)\n\n# Write dim_time to S3\ndim_time.write.mode(\"overwrite\").parquet(\"s3://ecommerce-pipeline-milan/dim/time/\")\n\njob.commit()"
}